{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b36c66a",
   "metadata": {},
   "source": [
    "# UFS Weather Model: Repository Tag Versions to Datasets\n",
    "\n",
    "__Introduction:__\n",
    "\n",
    "Each unique code release version of NOAA's Unified Forecast System (UFS) weather model repository points to the datasets for which its code release version utilizes. These datasets include the input data required by the UFS weather model and the baseline data required for performing the regression tests of various UFS applications. The names of the datasets are timestamped and hard-coded into each unique code release version framework (aka \"Github Tags\"). This script will provide users/developers of the UFS weather model repository and its associated repositories a more user friendly way of determining which input and baseline datasets should be utilized for a given code release version of the UFS weather model repository. \n",
    "\n",
    "\n",
    "__Purpose:__\n",
    "\n",
    "The purpose of this script is to extract the unique names of the timestamped input and baseline datasets (e.g. __input_data_YYYYMMDD__) for a given UFS weather model repository's code release version. To avoid users/developers from searching for the hard-coded timestamped names of the datasets within the code for a given UFS weather model repository release version, the extraction and mapping of the timestamped datasets to UFS weather model code release version will provide a more user friendly way for users/ developers to determine which dataset is being utilized for a given code release version. \n",
    "\n",
    "__Capabilities:__\n",
    "\n",
    "This script will be able to perform the following actions:\n",
    "\n",
    "- As release versions of the UFS weather model repository are being pushed out onto Github, this script will be able to extract each UFS weather model repository release version's name and access the scripts pointing to their corresponding timestamped input and baseline datasets directly from Github.\n",
    "\n",
    "- Provide an information regarding a given Github repository such as:\n",
    "    - Repository's name\n",
    "    - Repository's description\n",
    "    - Repository's created date.\n",
    "    - Repository's number of tags\n",
    "    - Repository's list of release versions/tags\n",
    "    - Repository's number of forks\n",
    "    - Repository's programming language\n",
    "    - Repository's number of stars\n",
    "\n",
    "- Provide a map/dictionary/table of the most recent UFS code release versions/tags to their corresponding timestamped input and baseline datasets.\n",
    "        \n",
    "\n",
    "__Future Capabilities:__\n",
    "\n",
    "- With additional features added to this script, the script can be utilized for mapping the release versions of the Short Range Weather (SRW) model and Mid-Range Weather (MRW) model repository to their respective timestamped datasets. \n",
    "\n",
    "__Prerequisites:__\n",
    "\n",
    "- This script utilizes the Github API. The Github API will cap a user from making N number of requests from its Github server within a narrow window of 1-2 hours, thus it is advise that the user of this script logs in with thier Github credentials when using the Github API to maximize the number of requests they can make from the Github server.\n",
    "\n",
    "\n",
    "__Version:__\n",
    "- Draft as of 02/23/22\n",
    "\n",
    "__Reference(s):__\n",
    "\n",
    "- N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ed723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "class get_tag2data():\n",
    "    \"\"\"\n",
    "        Scrapes & maps UFS weather model release version on Github to their corresponding required datasets.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, github_user = \"ufs-community\"):\n",
    "        \n",
    "        # Github login credentials if logging into Github API\n",
    "        self.github_user = github_user\n",
    "        \n",
    "        # Name of Github user sourcing the repository of interest.\n",
    "        self.gh_user = self.get_user_login()\n",
    "        \n",
    "        # List of Github user's repositories of interest.\n",
    "        self.user_repos = self.get_user_repos()\n",
    "        self.ufs_model_repo = self.user_repos['ufs-community/ufs-weather-model']\n",
    "        self.srw_repo = self.user_repos['ufs-community/ufs-srweather-app']\n",
    "        self.mrw_repo = self.user_repos['ufs-community/ufs-mrweather-app']\n",
    "\n",
    "    def get_user_login(self):\n",
    "        \"\"\"\n",
    "        Instantiate github user login.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "        \n",
    "        Return (object): Instantiated Github user's login object.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # If using Github login credentials.\n",
    "        #user=str(<Your Github User Account Name>)\n",
    "        #p=str(<Your Github User Account Credential>)\n",
    "        #gh = Github(user,p)\n",
    "        \n",
    "        # If not using Github login credentials.\n",
    "        gh = Github()\n",
    "        gh_user = gh.get_user(self.github_user)\n",
    "        \n",
    "        return gh_user \n",
    "    \n",
    "    def get_user_repos(self):\n",
    "        \"\"\"\n",
    "        Extract repositories of Github user sourcing the repositories of interest.\n",
    "        \n",
    "        Args: \n",
    "            None\n",
    "            \n",
    "        Return (dict): Dictionary of Github user's repositories.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Map repository name to repository location.\n",
    "        user_repos = {}\n",
    "        for repo in self.gh_user.get_repos():\n",
    "            user_repos[repo.full_name] = repo\n",
    "            \n",
    "        return user_repos\n",
    "        \n",
    "    def get_repo_details(self, repo):\n",
    "        \"\"\"\n",
    "        Extracts a repository's details.\n",
    "        \n",
    "        Args:\n",
    "            repo (object): Instantiated Github user's login object.\n",
    "            \n",
    "        Return (dict): Details of github repository.\n",
    "        \n",
    "        \"\"\"\n",
    "        repo_details = {}\n",
    "        \n",
    "        # Repository name & details.\n",
    "        repo_details['Name'] = repo.full_name\n",
    "        repo_details['Description'] = repo.description \n",
    "        \n",
    "        # Repository release version/tag name\n",
    "        tags_list = []\n",
    "        tag_names = []\n",
    "        for tag in ufs_model_repo.get_tags():\n",
    "            tags_list.append(tag)\n",
    "            tag_names.append(tag.name)\n",
    "        repo_details['Num_Tags'] = len(tags_list)\n",
    "        repo_details['Tag_Names'] = tag_names\n",
    "        #repo_details['Tags'] = tags_list\n",
    "        \n",
    "        # Repository created date\n",
    "        repo_details['Date_Created'] = repo.created_at\n",
    "        \n",
    "        # Repository last git push date.\n",
    "        repo_details['Date_Last_Push'] = repo.pushed_at\n",
    "        \n",
    "        # Repository webpage (if present).\n",
    "        repo_details['Webpage'] = repo.homepage\n",
    "        \n",
    "        # Repository programming language.\n",
    "        repo_details['Description'] = repo.language\n",
    "        \n",
    "        # Repository total forks.\n",
    "        repo_details['Num_forks'] = repo.forks\n",
    "        \n",
    "        # Repository total stars.\n",
    "        repo_details['Num_stars'] = repo.stargazers_count     \n",
    "        \n",
    "        return repo_details\n",
    "    \n",
    "    def get_file_content(self, repo, file_dir, tag_name):\n",
    "        \"\"\"\n",
    "        Extracts details of a given repository release version's script or file of interest.\n",
    "        \n",
    "        Args:\n",
    "            repo (object): Instantiated Github user's login object.\n",
    "            file_dir (str): File directory (relative to repo) of the file of interest.\n",
    "            tag_name (str): Tag name of interest.\n",
    "            \n",
    "        Return (dict): Details of a given repository release version's script or file of interest.\n",
    "        \n",
    "        This method is called by the \"get_tag2data(repo, repo_details)\" method.\n",
    "        \n",
    "        \"\"\"\n",
    "        contents = repo.get_contents(file_dir, ref = tag_name)\n",
    "        byte_list = contents.decoded_content.split(b'\\n')\n",
    "        str_txt = [byte_txt.decode(\"utf-8\") for byte_txt in byte_list]\n",
    "        \n",
    "        return str_txt\n",
    "    \n",
    "    def get_tag2data(self, repo, repo_details):\n",
    "        \"\"\"\n",
    "        Extracts repository release version's dataset for the UFS weather model repositories.\n",
    "        \n",
    "        **TODO: Create for SRW and MRW. Currenly, have dataset version extraction for RT.**\n",
    "        \n",
    "        Args:\n",
    "            repo (object): Instantiated Github user's login object.\n",
    "            repo_details (dict): Details of github repository.\n",
    "            \n",
    "        Return (list, dict): Text of github repository's script containing the filenames\n",
    "        of the input datasets used. For example, for the UFS weather model's RT framework,\n",
    "        rt.sh sets the baseline and input datasets utilized for its framework. Dictionary of \n",
    "        text mentioning dataset version per tag.\n",
    "        \n",
    "        This method will call the \"get_tag2data(repo, repo_details)\" method to extract the contents \n",
    "        of a requested file from a repository's release version.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Extract repository's name.\n",
    "        repo_type = os.path.split(ufs_model_details['Name'])[1]\n",
    "                                  \n",
    "        # Locate text containing dataset version per release version of UFS weather model repository.\n",
    "        tag_file_text = {}\n",
    "        if repo_type == 'ufs-weather-model':     \n",
    "            \n",
    "            # File of interest which points to baseline & input datasets\n",
    "            file_dir = \"tests/rt.sh\"\n",
    "            tag2dataset = {\"BL_DATE\":{},\n",
    "                           \"RTPWD\":{},\n",
    "                           \"INPUTDATA_ROOT\": {},\n",
    "                           \"INPUTDATA_ROOT_WW3\":{},\n",
    "                           \"INPUTDATA_ROOT_BMIC\": {}}\n",
    "            \n",
    "            # Extract content of the file of interest for a given release version.\n",
    "            for tag_name in repo_details['Tag_Names']:\n",
    "                #time.sleep(15)\n",
    "                script_content = self.get_file_content(repo, file_dir, tag_name)\n",
    "                tag_file_text[tag_name] = script_content\n",
    "                                  \n",
    "            for tag_name, script_body in tag_file_text.items():\n",
    "                \n",
    "                # Extract baseline datasets' name pointed by release version.\n",
    "                tag2dataset[\"BL_DATE\"][tag_name] = [match for match in script_body if \"BL_DATE\" in match]\n",
    "                tag2dataset[\"RTPWD\"][tag_name] = [match for match in script_body if \"RTPWD=${RTPWD:\" in match]\n",
    "                \n",
    "                # Extract input datasets' name pointed by release version.\n",
    "                tag2dataset[\"INPUTDATA_ROOT\"][tag_name] = [match for match in script_body if \"INPUTDATA_ROOT=${INPUTDATA_ROOT:\" in match]\n",
    "                tag2dataset[\"INPUTDATA_ROOT_WW3\"][tag_name] = [match for match in script_body if \"INPUTDATA_ROOT_WW3=${INPUTDATA_ROOT}\" in match]\n",
    "                tag2dataset[\"INPUTDATA_ROOT_BMIC\"][tag_name] = [match for match in script_body if \"INPUTDATA_ROOT_BMIC=${INPUTDATA_ROOT_BMIC:\" in match]\n",
    "                \n",
    "        return tag_file_text, tag2dataset\n",
    "\n",
    "    def preprocess_tag2data(self, raw_tag2dataset, framework_name):\n",
    "        \"\"\"\n",
    "        Preprocess raw text of the tags to dataset names.\n",
    "\n",
    "        Args:\n",
    "            raw_tag2dataset (dict): Dictionary of raw text mentioning dataset version per tag.\n",
    "            framework_name (str): Framework name (e.g. rt, srw, mrw) representing raw text \n",
    "                                  mentioning dataset version per tag.\n",
    "\n",
    "        Return (dict): Dictionaries mapping each UFS weather model's release version to \n",
    "        their corresponding baseline and input dataset names.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # === Preprocesses for baseline dataset version. ===\n",
    "        # Dictionary of directory path of baseline timestamp utilized for given tag version.\n",
    "        baseline_tuples_dict = {}\n",
    "\n",
    "        # Dictionary of release versions' baseline datasets.\n",
    "        baseline_versions = {}\n",
    "\n",
    "        # Dictionary of directory paths to baseline datasets w/ baseline timestamp name.\n",
    "        baseline_data_dict = {}\n",
    "\n",
    "        # Dictionary of baseline dataset timestamps. \n",
    "        baseline_data_dates = {}\n",
    "\n",
    "        # Detect all RTPWD mentions with data directory.\n",
    "        # Note: BL_DATE may not be mentioned in a release ver. rather in some cases date is factored into RTPWD.\n",
    "        # Depending on the tag version, rt framework may have two different datasets that it will accept -- platform specified.\n",
    "        for k,v_list in raw_tag2dataset['RTPWD'].items():\n",
    "            baseline_dirs = []\n",
    "            baseline_dates = []\n",
    "            for line in v_list:\n",
    "                partition_line = line.lstrip().split('/')\n",
    "                if not any(value in line for value in ('^^')) and k not in baseline_data_dict:\n",
    "\n",
    "                    # Extract list of baseline directory paths.\n",
    "                    baseline_dirs.append(partition_line[-2] + '/' + partition_line[-1].replace('}',''))\n",
    "\n",
    "                    # Extract list of baseline dataset timestamps.\n",
    "                    baseline_dates.append(partition_line[-1].replace('}','').replace('{','').replace('$',''))\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # Extract list of baseline directory paths.\n",
    "                    baseline_dirs.append(partition_line[-3] + '/' + partition_line[-2] + '/' + partition_line[-1])\n",
    "\n",
    "                    # Extract list of baseline dataset timestamps.\n",
    "                    baseline_dates.append(partition_line[-2].replace('}','').replace('{','').replace('$',''))\n",
    "\n",
    "            # List of RTPWD dataset versions called for given tag version.(paths)\n",
    "            # Note: *** TODO: Checked if Hera /scratch1/NCEPDEV/nems/emc.nemspara/RT/ contains data version.\n",
    "            # Data set version for tag does not exist on Hera -- keep unique path to note this.****\n",
    "            baseline_tuples_dict[framework_name, k, 'BL_INPUT'] = list(set(baseline_dirs))\n",
    "\n",
    "            # List of RTPWD dataset versions called for given tag version.(dates)\n",
    "            # Note: *** TODO: Checked if Hera /scratch1/NCEPDEV/nems/emc.nemspara/RT/ contains data version.\n",
    "            # Data set version for tag does not exist on Hera -- keep unique path to note this.****\n",
    "            baseline_versions[framework_name, k, 'BL_INPUT'] = list(set(baseline_dates))\n",
    "\n",
    "        # Detect all BL_DATE mentions with data directory. Writes over tags' value for which contains BL_DATE.\n",
    "        for k,v_list in raw_tag2dataset['BL_DATE'].items():\n",
    "            for line in v_list:\n",
    "                if any(value in line for value in ('^^')):\n",
    "                    partition_line = line.lstrip().split('/')\n",
    "                    model_name = line.split('/')[-3]\n",
    "\n",
    "                if not any(value in line for value in ('$')):\n",
    "                    partition_line = line.split('=')\n",
    "                    model_name = 'NEMSfv3gfs' # TODO: Return back to extract modelname of dataset\n",
    "\n",
    "                    # Dataset path\n",
    "                    baseline_tuples_dict[framework_name, k, 'BL_INPUT'] = model_name + '/develop-' + partition_line[-1]\n",
    "\n",
    "                    # Data version\n",
    "                    baseline_versions[framework_name, k, 'BL_INPUT'] = ['develop-' + partition_line[-1]]\n",
    "\n",
    "        # Nested baseline data dictionary (paths).            \n",
    "        for (framework, tag_name, input_type), data_version in baseline_tuples_dict.items():\n",
    "            baseline_data_dict.setdefault(framework, {}).setdefault(tag_name, {})[input_type] = data_version\n",
    "\n",
    "        # Nested baseline data dictionary (dates)       \n",
    "        for (framework, tag_name, input_type), data_version in baseline_versions.items():\n",
    "            baseline_data_dates.setdefault(framework, {}).setdefault(tag_name, {})[input_type] = data_version\n",
    "\n",
    "        # === Preprocesses for input dataset version. ===\n",
    "        # Dictionary of directory path of input timestamp utilized for given tag version.\n",
    "        input_tuples_dict = {}\n",
    "        \n",
    "        # Dictionary of directory paths to input datasets w/ input timestamp name.\n",
    "        input_data_dict = {}\n",
    "        \n",
    "        # Dictionary of release versions' input datasets.\n",
    "        input_versions = {}\n",
    "        \n",
    "        # Dictionary of input dataset timestamps. \n",
    "        input_data_dates = {}\n",
    "\n",
    "        # Detect all INPUTDATA_ROOT mentions with data directory.\n",
    "        # Note: There are three different variables defined to distinguish the input data categories (e.g. \"main\" root, WW3, BMIC)\n",
    "        for k,v_list in raw_tag2dataset['INPUTDATA_ROOT'].items():\n",
    "            for line in v_list:\n",
    "                partition_line = line.split('/')\n",
    "                if partition_line[-1] =='}':\n",
    "\n",
    "                    # Update dict w/ input datasets' directory path.\n",
    "                    input_tuples_dict[framework_name, k, 'INPUTDATA_ROOT'] = partition_line[-3] + '/' + partition_line[-2].replace('}','')\n",
    "\n",
    "                    # Update dict w/ input datasets' timestamp.\n",
    "                    input_versions[framework_name, k, 'INPUTDATA_ROOT'] = partition_line[-2].replace('}','')\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # Update dict w/ input datasets' directory path.\n",
    "                    input_tuples_dict[framework_name, k, 'INPUTDATA_ROOT'] = partition_line[-2] + '/' + partition_line[-1].replace('}','')\n",
    "\n",
    "                    # Update dict w/ input datasets' timestamp.\n",
    "                    input_versions[framework_name, k, 'INPUTDATA_ROOT'] = partition_line[-1].replace('}','')\n",
    "\n",
    "        # Detect all INPUTDATA_ROOT_WW3 mentions with data directory.\n",
    "        for k,v_list in raw_tag2dataset['INPUTDATA_ROOT_WW3'].items():\n",
    "            for line in v_list:\n",
    "                partition_line = line.split('/')\n",
    "\n",
    "                # Dataset path.\n",
    "                input_tuples_dict[framework_name, k, 'INPUTDATA_ROOT_WW3'] = partition_line[-1]\n",
    "\n",
    "                # Data version.\n",
    "                input_versions[framework_name, k, 'INPUTDATA_ROOT_WW3'] = partition_line[-1]\n",
    "\n",
    "        # Detect all INPUTDATA_ROOT_BMIC mentions with data directory.\n",
    "        for k,v_list in raw_tag2dataset['INPUTDATA_ROOT_BMIC'].items():\n",
    "            for line in v_list:\n",
    "                partition_line = line.split('/')\n",
    "\n",
    "                # Dataset path.\n",
    "                input_tuples_dict[framework_name, k, 'INPUTDATA_ROOT_BMIC'] = partition_line[-1].replace('}','')\n",
    "\n",
    "                # Data version.\n",
    "                input_versions[framework_name, k, 'INPUTDATA_ROOT_BMIC'] = partition_line[-1].replace('}','')\n",
    "\n",
    "        # Generate nested dictionary. Update w/ input datasets' directory paths.\n",
    "        for (framework, tag_name, input_type), data_version in input_tuples_dict.items():\n",
    "            input_data_dict.setdefault(framework, {}).setdefault(tag_name, {})[input_type] = data_version\n",
    "\n",
    "        # Generate newsted dictionary. Update w/ input datasets' timestamp dates.\n",
    "        for (framework, tag_name, input_type), data_version in input_versions.items():\n",
    "            input_data_dates.setdefault(framework, {}).setdefault(tag_name, {})[input_type] = data_version\n",
    "\n",
    "        # Save baseline & input data details per release version maps to pickle files.\n",
    "        self.save2pickle(baseline_data_dict, f'{framework_name}_baseline_data')\n",
    "        self.save2pickle(input_data_dict, f'{framework_name}_input_data')\n",
    "        self.save2pickle(baseline_data_dates, f'{framework_name}_baseline_data_dates')\n",
    "        self.save2pickle(input_data_dates, f'{framework_name}_input_data_dates')\n",
    "        \n",
    "        return baseline_data_dict, input_data_dict, baseline_data_dates, input_data_dates\n",
    "\n",
    "    def save2pickle(self, data2save, fn):\n",
    "        \"\"\"\n",
    "        Save data to pickle file.\n",
    "        \n",
    "        Args:\n",
    "            data2save (dict, str, tuple, list, pd.DataFrame): Data to save.\n",
    "            fn (str): Filename for pickle file. \n",
    "        \n",
    "        Return : None\n",
    "        \n",
    "        \"\"\"\n",
    "        with open(fn + '.pkl', 'wb') as file:\n",
    "            pickle.dump(data2save, file)\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def read_pickle(self, fn):\n",
    "        \"\"\"\n",
    "        Read data from pickle file.\n",
    "        \n",
    "        Args:\n",
    "            fn (str): Filename of pickle file. \n",
    "        \n",
    "        Return (dict, str, tuple, list, pd.DataFrame): Pickle file's content. \n",
    "        \n",
    "        \"\"\"\n",
    "        with open(fn + '.pkl', 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1dbe4",
   "metadata": {},
   "source": [
    "# Demo\n",
    "\n",
    "## Github Repositories of Interest.\n",
    "\n",
    "| Repo. Description | GitHub Location |\n",
    "| :- | :- |\n",
    "| __Unified Forecast System (UFS) Model Repository__ | _ufs-community/ufs-weather-model_|\n",
    "| __Short-Range Weather (SRW) Model Repository__ | _ufs-community/ufs-srweather-app_ |\n",
    "| __Medium_Range Weather (MRW) Model Repository__ | _ufs-community/ufs-mrweather-app_ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a461c6e",
   "metadata": {},
   "source": [
    "# Instantiate Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7171ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo.\n",
    "tag2data_wrapper = get_tag2data()\n",
    "\n",
    "# UFS weather model repository.\n",
    "ufs_model_repo = tag2data_wrapper.ufs_model_repo\n",
    "ufs_model_details = tag2data_wrapper.get_repo_details(ufs_model_repo)\n",
    "\n",
    "# Locating dataset version per release version of UFS weather model repository.\n",
    "tag_file_text, raw_tag2dataset = tag2data_wrapper.get_tag2data(ufs_model_repo, ufs_model_details)\n",
    "\n",
    "# Preprocess raw text of the tags to determine their unique dataset names.\n",
    "framework_name = 'rt'\n",
    "baseline_data_dict, input_data_dict, baseline_data_dates, input_data_dates = tag2data_wrapper.preprocess_tag2data(raw_tag2dataset, framework_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32913929",
   "metadata": {},
   "source": [
    "# Mapped Timestamped Baseline Dataset to UFS Repository Code Version/Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97eb3124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BL_INPUT</th>\n",
       "      <th>BL_INPUT1</th>\n",
       "      <th>BL_INPUT2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ufs-v2.0.0</th>\n",
       "      <td>[ufs-public-release-v2-20210212]</td>\n",
       "      <td>ufs-public-release-v2-20210212</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ufs-v1.1.0</th>\n",
       "      <td>[ufs-public-release-20200728]</td>\n",
       "      <td>ufs-public-release-20200728</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ufs-v1.0.0</th>\n",
       "      <td>[ufs-public-release-20200224]</td>\n",
       "      <td>ufs-public-release-20200224</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release/P8a</th>\n",
       "      <td>[develop-20211222]</td>\n",
       "      <td>develop-20211222</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release/P7c</th>\n",
       "      <td>[develop-20210820]</td>\n",
       "      <td>develop-20210820</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datm_mom6_cice6_cmeps</th>\n",
       "      <td>[develop-20201215]</td>\n",
       "      <td>develop-20201215</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccpp_ipd_comparison</th>\n",
       "      <td>[develop-20200923]</td>\n",
       "      <td>develop-20200923</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prototype-6.0beta</th>\n",
       "      <td>[develop-20210217]</td>\n",
       "      <td>develop-20210217</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFSv16_CCPP</th>\n",
       "      <td>[develop-20201214]</td>\n",
       "      <td>develop-20201214</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.2.0</th>\n",
       "      <td>[develop-20200626]</td>\n",
       "      <td>develop-20200626</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.17</th>\n",
       "      <td>[develop-20200626]</td>\n",
       "      <td>develop-20200626</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.16</th>\n",
       "      <td>[develop-20200626]</td>\n",
       "      <td>develop-20200626</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.15</th>\n",
       "      <td>[develop-20200626]</td>\n",
       "      <td>develop-20200626</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.14</th>\n",
       "      <td>[develop-20200626]</td>\n",
       "      <td>develop-20200626</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.13</th>\n",
       "      <td>[develop-20200210, develop-20200626]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>develop-20200626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.12</th>\n",
       "      <td>[develop-20200210, develop-20200626]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>develop-20200626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.11</th>\n",
       "      <td>[develop-20200210, develop-20200626]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>develop-20200626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.10</th>\n",
       "      <td>[develop-20200210, develop-20200624]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>develop-20200624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.9</th>\n",
       "      <td>[develop-20200210, develop-20200624]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>develop-20200624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.8</th>\n",
       "      <td>[develop-20200210, develop-20200624]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>develop-20200624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.7</th>\n",
       "      <td>[develop-20200210]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.6</th>\n",
       "      <td>[develop-20200210]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.5</th>\n",
       "      <td>[develop-20200210]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.4</th>\n",
       "      <td>[develop-20200210]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.3</th>\n",
       "      <td>[develop-20200210]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.2</th>\n",
       "      <td>[develop-20200210]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.1</th>\n",
       "      <td>[develop-20200210]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS.v16.0.0</th>\n",
       "      <td>[develop-20200210]</td>\n",
       "      <td>develop-20200210</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS_v15.2.1</th>\n",
       "      <td>[trunk-20180605]</td>\n",
       "      <td>trunk-20180605</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS_v15.2.0</th>\n",
       "      <td>[trunk-20180605]</td>\n",
       "      <td>trunk-20180605</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS_v15.1.4</th>\n",
       "      <td>[trunk-20180605]</td>\n",
       "      <td>trunk-20180605</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS_v15.1.3</th>\n",
       "      <td>[trunk-20180605]</td>\n",
       "      <td>trunk-20180605</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS_v15.1.2</th>\n",
       "      <td>[trunk-20180605]</td>\n",
       "      <td>trunk-20180605</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFS_v15.1.1</th>\n",
       "      <td>[trunk-20180605]</td>\n",
       "      <td>trunk-20180605</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   BL_INPUT  \\\n",
       "ufs-v2.0.0                 [ufs-public-release-v2-20210212]   \n",
       "ufs-v1.1.0                    [ufs-public-release-20200728]   \n",
       "ufs-v1.0.0                    [ufs-public-release-20200224]   \n",
       "release/P8a                              [develop-20211222]   \n",
       "release/P7c                              [develop-20210820]   \n",
       "datm_mom6_cice6_cmeps                    [develop-20201215]   \n",
       "ccpp_ipd_comparison                      [develop-20200923]   \n",
       "Prototype-6.0beta                        [develop-20210217]   \n",
       "GFSv16_CCPP                              [develop-20201214]   \n",
       "GFS.v16.2.0                              [develop-20200626]   \n",
       "GFS.v16.0.17                             [develop-20200626]   \n",
       "GFS.v16.0.16                             [develop-20200626]   \n",
       "GFS.v16.0.15                             [develop-20200626]   \n",
       "GFS.v16.0.14                             [develop-20200626]   \n",
       "GFS.v16.0.13           [develop-20200210, develop-20200626]   \n",
       "GFS.v16.0.12           [develop-20200210, develop-20200626]   \n",
       "GFS.v16.0.11           [develop-20200210, develop-20200626]   \n",
       "GFS.v16.0.10           [develop-20200210, develop-20200624]   \n",
       "GFS.v16.0.9            [develop-20200210, develop-20200624]   \n",
       "GFS.v16.0.8            [develop-20200210, develop-20200624]   \n",
       "GFS.v16.0.7                              [develop-20200210]   \n",
       "GFS.v16.0.6                              [develop-20200210]   \n",
       "GFS.v16.0.5                              [develop-20200210]   \n",
       "GFS.v16.0.4                              [develop-20200210]   \n",
       "GFS.v16.0.3                              [develop-20200210]   \n",
       "GFS.v16.0.2                              [develop-20200210]   \n",
       "GFS.v16.0.1                              [develop-20200210]   \n",
       "GFS.v16.0.0                              [develop-20200210]   \n",
       "GFS_v15.2.1                                [trunk-20180605]   \n",
       "GFS_v15.2.0                                [trunk-20180605]   \n",
       "GFS_v15.1.4                                [trunk-20180605]   \n",
       "GFS_v15.1.3                                [trunk-20180605]   \n",
       "GFS_v15.1.2                                [trunk-20180605]   \n",
       "GFS_v15.1.1                                [trunk-20180605]   \n",
       "\n",
       "                                            BL_INPUT1         BL_INPUT2  \n",
       "ufs-v2.0.0             ufs-public-release-v2-20210212              None  \n",
       "ufs-v1.1.0                ufs-public-release-20200728              None  \n",
       "ufs-v1.0.0                ufs-public-release-20200224              None  \n",
       "release/P8a                          develop-20211222              None  \n",
       "release/P7c                          develop-20210820              None  \n",
       "datm_mom6_cice6_cmeps                develop-20201215              None  \n",
       "ccpp_ipd_comparison                  develop-20200923              None  \n",
       "Prototype-6.0beta                    develop-20210217              None  \n",
       "GFSv16_CCPP                          develop-20201214              None  \n",
       "GFS.v16.2.0                          develop-20200626              None  \n",
       "GFS.v16.0.17                         develop-20200626              None  \n",
       "GFS.v16.0.16                         develop-20200626              None  \n",
       "GFS.v16.0.15                         develop-20200626              None  \n",
       "GFS.v16.0.14                         develop-20200626              None  \n",
       "GFS.v16.0.13                         develop-20200210  develop-20200626  \n",
       "GFS.v16.0.12                         develop-20200210  develop-20200626  \n",
       "GFS.v16.0.11                         develop-20200210  develop-20200626  \n",
       "GFS.v16.0.10                         develop-20200210  develop-20200624  \n",
       "GFS.v16.0.9                          develop-20200210  develop-20200624  \n",
       "GFS.v16.0.8                          develop-20200210  develop-20200624  \n",
       "GFS.v16.0.7                          develop-20200210              None  \n",
       "GFS.v16.0.6                          develop-20200210              None  \n",
       "GFS.v16.0.5                          develop-20200210              None  \n",
       "GFS.v16.0.4                          develop-20200210              None  \n",
       "GFS.v16.0.3                          develop-20200210              None  \n",
       "GFS.v16.0.2                          develop-20200210              None  \n",
       "GFS.v16.0.1                          develop-20200210              None  \n",
       "GFS.v16.0.0                          develop-20200210              None  \n",
       "GFS_v15.2.1                            trunk-20180605              None  \n",
       "GFS_v15.2.0                            trunk-20180605              None  \n",
       "GFS_v15.1.4                            trunk-20180605              None  \n",
       "GFS_v15.1.3                            trunk-20180605              None  \n",
       "GFS_v15.1.2                            trunk-20180605              None  \n",
       "GFS_v15.1.1                            trunk-20180605              None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For baseline dataset paths:\n",
    "# baseline_data_dict['rt']\n",
    "\n",
    "# For baseline dataset timestamps:\n",
    "bl2tag_dict = baseline_data_dates['rt']\n",
    "bl2tag_df = pd.DataFrame(bl2tag_dict).T\n",
    "bl2tag_df[['BL_INPUT1', 'BL_INPUT2']] = pd.DataFrame(bl2tag_df.BL_INPUT.tolist(), index=bl2tag_df.index)\n",
    "bl2tag_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc747d0",
   "metadata": {},
   "source": [
    "# Mapped Timestamped Input Dataset to UFS Repository Code Version/Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32370417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INPUTDATA_ROOT</th>\n",
       "      <th>INPUTDATA_ROOT_WW3</th>\n",
       "      <th>INPUTDATA_ROOT_BMIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>release/P8a</th>\n",
       "      <td>input-data-20211210</td>\n",
       "      <td>WW3_input_data_20211113</td>\n",
       "      <td>BM_IC-20210717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release/P7c</th>\n",
       "      <td>input-data-20210717</td>\n",
       "      <td>WW3_input_data_20210621</td>\n",
       "      <td>BM_IC-20210717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datm_mom6_cice6_cmeps</th>\n",
       "      <td>input-data-20201201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prototype-6.0beta</th>\n",
       "      <td>input-data-20210212</td>\n",
       "      <td>WW3_input_data_20201220</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFSv16_CCPP</th>\n",
       "      <td>input-data-20201201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            INPUTDATA_ROOT       INPUTDATA_ROOT_WW3  \\\n",
       "release/P8a            input-data-20211210  WW3_input_data_20211113   \n",
       "release/P7c            input-data-20210717  WW3_input_data_20210621   \n",
       "datm_mom6_cice6_cmeps  input-data-20201201                      NaN   \n",
       "Prototype-6.0beta      input-data-20210212  WW3_input_data_20201220   \n",
       "GFSv16_CCPP            input-data-20201201                      NaN   \n",
       "\n",
       "                      INPUTDATA_ROOT_BMIC  \n",
       "release/P8a                BM_IC-20210717  \n",
       "release/P7c                BM_IC-20210717  \n",
       "datm_mom6_cice6_cmeps                 NaN  \n",
       "Prototype-6.0beta                     NaN  \n",
       "GFSv16_CCPP                           NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For input dataset paths:\n",
    "#input_data_dict['rt']\n",
    "\n",
    "# For input dataset timestamps:\n",
    "input2tag_dict = input_data_dates['rt']\n",
    "input2tag_df = pd.DataFrame(input2tag_dict).T\n",
    "input2tag_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efaa833",
   "metadata": {},
   "source": [
    "# Evaluate Input & Baseline Paths Saved as Pickle Files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f94532",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_baseline = tag2data_wrapper.read_pickle('rt_baseline_data')\n",
    "rt_input = tag2data_wrapper.read_pickle('rt_input_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31c4ca",
   "metadata": {},
   "source": [
    "#### Map of UFS Version Code to Baseline Dataset 'BL_INPUT' Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e6accfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ufs-v2.0.0': {'BL_INPUT': ['NEMSfv3gfs/ufs-public-release-v2-20210212/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/ufs-public-release-v2-20210212']},\n",
       " 'ufs-v1.1.0': {'BL_INPUT': ['NEMSfv3gfs/ufs-public-release-20200728',\n",
       "   'RTPWD=${RTPWD:-$DISKNM/ufs-public-release-20200728/${COMPILER^^}}']},\n",
       " 'ufs-v1.0.0': {'BL_INPUT': ['NEMSfv3gfs/ufs-public-release-20200224',\n",
       "   'RTPWD=${RTPWD:-$DISKNM/ufs-public-release-20200224/${COMPILER^^}}']},\n",
       " 'release/P8a': {'BL_INPUT': 'NEMSfv3gfs/develop-20211222'},\n",
       " 'release/P7c': {'BL_INPUT': 'NEMSfv3gfs/develop-20210820'},\n",
       " 'datm_mom6_cice6_cmeps': {'BL_INPUT': ['NEMSfv3gfs/develop-20201215',\n",
       "   'NEMSfv3gfs/develop-20201215/${RT_COMPILER^^}}']},\n",
       " 'ccpp_ipd_comparison': {'BL_INPUT': ['NEMSfv3gfs/develop-20200923',\n",
       "   'NEMSfv3gfs/develop-20200923/${RT_COMPILER^^}}']},\n",
       " 'Prototype-6.0beta': {'BL_INPUT': ['NEMSfv3gfs/develop-20210217',\n",
       "   'NEMSfv3gfs/develop-20210217/${RT_COMPILER^^}}']},\n",
       " 'GFSv16_CCPP': {'BL_INPUT': ['NEMSfv3gfs/develop-20201214',\n",
       "   'NEMSfv3gfs/develop-20201214/${RT_COMPILER^^}}']},\n",
       " 'GFS.v16.2.0': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200626/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200626']},\n",
       " 'GFS.v16.0.17': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200626/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200626']},\n",
       " 'GFS.v16.0.16': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200626/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200626']},\n",
       " 'GFS.v16.0.15': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200626/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200626']},\n",
       " 'GFS.v16.0.14': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200626/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200626']},\n",
       " 'GFS.v16.0.13': {'BL_INPUT': ['NEMSfv3gfs/develop-20200626',\n",
       "   'RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}']},\n",
       " 'GFS.v16.0.12': {'BL_INPUT': ['NEMSfv3gfs/develop-20200626',\n",
       "   'RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}']},\n",
       " 'GFS.v16.0.11': {'BL_INPUT': ['NEMSfv3gfs/develop-20200626',\n",
       "   'RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}']},\n",
       " 'GFS.v16.0.10': {'BL_INPUT': ['NEMSfv3gfs/develop-20200624',\n",
       "   'RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}']},\n",
       " 'GFS.v16.0.9': {'BL_INPUT': ['NEMSfv3gfs/develop-20200624',\n",
       "   'RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}']},\n",
       " 'GFS.v16.0.8': {'BL_INPUT': ['NEMSfv3gfs/develop-20200624',\n",
       "   'RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}']},\n",
       " 'GFS.v16.0.7': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200210']},\n",
       " 'GFS.v16.0.6': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200210']},\n",
       " 'GFS.v16.0.5': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200210']},\n",
       " 'GFS.v16.0.4': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200210']},\n",
       " 'GFS.v16.0.3': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200210']},\n",
       " 'GFS.v16.0.2': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200210']},\n",
       " 'GFS.v16.0.1': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200210']},\n",
       " 'GFS.v16.0.0': {'BL_INPUT': ['RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "   'NEMSfv3gfs/develop-20200210']},\n",
       " 'GFS_v15.2.1': {'BL_INPUT': ['NEMSfv3gfs/trunk-20180605']},\n",
       " 'GFS_v15.2.0': {'BL_INPUT': ['NEMSfv3gfs/trunk-20180605']},\n",
       " 'GFS_v15.1.4': {'BL_INPUT': ['NEMSfv3gfs/trunk-20180605']},\n",
       " 'GFS_v15.1.3': {'BL_INPUT': ['NEMSfv3gfs/trunk-20180605']},\n",
       " 'GFS_v15.1.2': {'BL_INPUT': ['NEMSfv3gfs/trunk-20180605']},\n",
       " 'GFS_v15.1.1': {'BL_INPUT': ['NEMSfv3gfs/trunk-20180605']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_baseline['rt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa84f7e",
   "metadata": {},
   "source": [
    "#### Map of UFS Version Code to Baseline Dataset 'RTPWD' Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79bc88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ufs-v2.0.0': ['  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/ufs-public-release-v2-20210212/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/ufs-public-release-v2-20210212}'],\n",
       " 'ufs-v1.1.0': ['  RTPWD=${RTPWD:-$DISKNM/ufs-public-release-20200728/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/ufs-public-release-20200728}'],\n",
       " 'ufs-v1.0.0': ['  RTPWD=${RTPWD:-$DISKNM/ufs-public-release-20200224/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/ufs-public-release-20200224}'],\n",
       " 'release/P8a': ['  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-${BL_DATE}/${RT_COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-${BL_DATE}}'],\n",
       " 'release/P7c': ['  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-${BL_DATE}/${RT_COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-${BL_DATE}}'],\n",
       " 'datm_mom6_cice6_cmeps': ['  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20201215/${RT_COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20201215}'],\n",
       " 'ccpp_ipd_comparison': ['  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200923/${RT_COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200923}'],\n",
       " 'Prototype-6.0beta': ['  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20210217/${RT_COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20210217}'],\n",
       " 'GFSv16_CCPP': ['  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20201214/${RT_COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20201214}'],\n",
       " 'GFS.v16.2.0': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200626/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200626}'],\n",
       " 'GFS.v16.0.17': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200626/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200626}'],\n",
       " 'GFS.v16.0.16': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200626/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200626}'],\n",
       " 'GFS.v16.0.15': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200626/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200626}'],\n",
       " 'GFS.v16.0.14': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200626/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200626}'],\n",
       " 'GFS.v16.0.13': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200626}'],\n",
       " 'GFS.v16.0.12': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200626}'],\n",
       " 'GFS.v16.0.11': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200626}'],\n",
       " 'GFS.v16.0.10': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200624}'],\n",
       " 'GFS.v16.0.9': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200624}'],\n",
       " 'GFS.v16.0.8': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200624}'],\n",
       " 'GFS.v16.0.7': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200210}'],\n",
       " 'GFS.v16.0.6': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200210}'],\n",
       " 'GFS.v16.0.5': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200210}'],\n",
       " 'GFS.v16.0.4': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200210}'],\n",
       " 'GFS.v16.0.3': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200210}'],\n",
       " 'GFS.v16.0.2': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200210}'],\n",
       " 'GFS.v16.0.1': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200210}'],\n",
       " 'GFS.v16.0.0': ['  RTPWD=${RTPWD:-$DISKNM/develop-20200210/${COMPILER^^}}',\n",
       "  '  RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/develop-20200210}'],\n",
       " 'GFS_v15.2.1': ['RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/trunk-20180605}'],\n",
       " 'GFS_v15.2.0': ['RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/trunk-20180605}'],\n",
       " 'GFS_v15.1.4': ['RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/trunk-20180605}'],\n",
       " 'GFS_v15.1.3': ['RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/trunk-20180605}'],\n",
       " 'GFS_v15.1.2': ['RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/trunk-20180605}'],\n",
       " 'GFS_v15.1.1': ['RTPWD=${RTPWD:-$DISKNM/NEMSfv3gfs/trunk-20180605}']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tag2dataset['RTPWD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6292ff3",
   "metadata": {},
   "source": [
    "#### Map of UFS Version Code to Input Dataset 'INPUTDATA_ROOT', 'INPUTDATA_ROOT_WW3', 'INPUTDATA_ROOT_BMIC' Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66bd1b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'release/P8a': {'INPUTDATA_ROOT': 'NEMSfv3gfs/input-data-20211210',\n",
       "  'INPUTDATA_ROOT_WW3': 'WW3_input_data_20211113',\n",
       "  'INPUTDATA_ROOT_BMIC': 'BM_IC-20210717'},\n",
       " 'release/P7c': {'INPUTDATA_ROOT': 'NEMSfv3gfs/input-data-20210717',\n",
       "  'INPUTDATA_ROOT_WW3': 'WW3_input_data_20210621',\n",
       "  'INPUTDATA_ROOT_BMIC': 'BM_IC-20210717'},\n",
       " 'datm_mom6_cice6_cmeps': {'INPUTDATA_ROOT': 'NEMSfv3gfs/input-data-20201201'},\n",
       " 'Prototype-6.0beta': {'INPUTDATA_ROOT': 'NEMSfv3gfs/input-data-20210212',\n",
       "  'INPUTDATA_ROOT_WW3': 'WW3_input_data_20201220'},\n",
       " 'GFSv16_CCPP': {'INPUTDATA_ROOT': 'NEMSfv3gfs/input-data-20201201'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_input['rt'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496d879",
   "metadata": {},
   "source": [
    "#### Map of UFS Version Code to Input Dataset 'INPUTDATA_ROOT' Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6217bacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ufs-v2.0.0': [],\n",
       " 'ufs-v1.1.0': [],\n",
       " 'ufs-v1.0.0': [],\n",
       " 'release/P8a': ['INPUTDATA_ROOT=${INPUTDATA_ROOT:-$DISKNM/NEMSfv3gfs/input-data-20211210}'],\n",
       " 'release/P7c': ['INPUTDATA_ROOT=${INPUTDATA_ROOT:-$DISKNM/NEMSfv3gfs/input-data-20210717}'],\n",
       " 'datm_mom6_cice6_cmeps': ['INPUTDATA_ROOT=${INPUTDATA_ROOT:-$DISKNM/NEMSfv3gfs/input-data-20201201/}'],\n",
       " 'ccpp_ipd_comparison': [],\n",
       " 'Prototype-6.0beta': ['INPUTDATA_ROOT=${INPUTDATA_ROOT:-$DISKNM/NEMSfv3gfs/input-data-20210212}'],\n",
       " 'GFSv16_CCPP': ['INPUTDATA_ROOT=${INPUTDATA_ROOT:-$DISKNM/NEMSfv3gfs/input-data-20201201/}'],\n",
       " 'GFS.v16.2.0': [],\n",
       " 'GFS.v16.0.17': [],\n",
       " 'GFS.v16.0.16': [],\n",
       " 'GFS.v16.0.15': [],\n",
       " 'GFS.v16.0.14': [],\n",
       " 'GFS.v16.0.13': [],\n",
       " 'GFS.v16.0.12': [],\n",
       " 'GFS.v16.0.11': [],\n",
       " 'GFS.v16.0.10': [],\n",
       " 'GFS.v16.0.9': [],\n",
       " 'GFS.v16.0.8': [],\n",
       " 'GFS.v16.0.7': [],\n",
       " 'GFS.v16.0.6': [],\n",
       " 'GFS.v16.0.5': [],\n",
       " 'GFS.v16.0.4': [],\n",
       " 'GFS.v16.0.3': [],\n",
       " 'GFS.v16.0.2': [],\n",
       " 'GFS.v16.0.1': [],\n",
       " 'GFS.v16.0.0': [],\n",
       " 'GFS_v15.2.1': [],\n",
       " 'GFS_v15.2.0': [],\n",
       " 'GFS_v15.1.4': [],\n",
       " 'GFS_v15.1.3': [],\n",
       " 'GFS_v15.1.2': [],\n",
       " 'GFS_v15.1.1': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tag2dataset['INPUTDATA_ROOT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542f51c",
   "metadata": {},
   "source": [
    "#### Map of UFS Version Code to Input Dataset 'INPUTDATA_ROOT_WW3' Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6425536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ufs-v2.0.0': [],\n",
       " 'ufs-v1.1.0': [],\n",
       " 'ufs-v1.0.0': [],\n",
       " 'release/P8a': ['INPUTDATA_ROOT_WW3=${INPUTDATA_ROOT}/WW3_input_data_20211113'],\n",
       " 'release/P7c': ['INPUTDATA_ROOT_WW3=${INPUTDATA_ROOT}/WW3_input_data_20210621'],\n",
       " 'datm_mom6_cice6_cmeps': [],\n",
       " 'ccpp_ipd_comparison': [],\n",
       " 'Prototype-6.0beta': ['INPUTDATA_ROOT_WW3=${INPUTDATA_ROOT}/WW3_input_data_20201220'],\n",
       " 'GFSv16_CCPP': [],\n",
       " 'GFS.v16.2.0': [],\n",
       " 'GFS.v16.0.17': [],\n",
       " 'GFS.v16.0.16': [],\n",
       " 'GFS.v16.0.15': [],\n",
       " 'GFS.v16.0.14': [],\n",
       " 'GFS.v16.0.13': [],\n",
       " 'GFS.v16.0.12': [],\n",
       " 'GFS.v16.0.11': [],\n",
       " 'GFS.v16.0.10': [],\n",
       " 'GFS.v16.0.9': [],\n",
       " 'GFS.v16.0.8': [],\n",
       " 'GFS.v16.0.7': [],\n",
       " 'GFS.v16.0.6': [],\n",
       " 'GFS.v16.0.5': [],\n",
       " 'GFS.v16.0.4': [],\n",
       " 'GFS.v16.0.3': [],\n",
       " 'GFS.v16.0.2': [],\n",
       " 'GFS.v16.0.1': [],\n",
       " 'GFS.v16.0.0': [],\n",
       " 'GFS_v15.2.1': [],\n",
       " 'GFS_v15.2.0': [],\n",
       " 'GFS_v15.1.4': [],\n",
       " 'GFS_v15.1.3': [],\n",
       " 'GFS_v15.1.2': [],\n",
       " 'GFS_v15.1.1': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tag2dataset['INPUTDATA_ROOT_WW3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2538cc",
   "metadata": {},
   "source": [
    "#### Map of UFS Version Code to Input Dataset 'INPUTDATA_ROOT_BMIC' Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e78605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ufs-v2.0.0': [],\n",
       " 'ufs-v1.1.0': [],\n",
       " 'ufs-v1.0.0': [],\n",
       " 'release/P8a': ['INPUTDATA_ROOT_BMIC=${INPUTDATA_ROOT_BMIC:-$DISKNM/NEMSfv3gfs/BM_IC-20210717}'],\n",
       " 'release/P7c': ['INPUTDATA_ROOT_BMIC=${INPUTDATA_ROOT_BMIC:-$DISKNM/NEMSfv3gfs/BM_IC-20210717}'],\n",
       " 'datm_mom6_cice6_cmeps': [],\n",
       " 'ccpp_ipd_comparison': [],\n",
       " 'Prototype-6.0beta': [],\n",
       " 'GFSv16_CCPP': [],\n",
       " 'GFS.v16.2.0': [],\n",
       " 'GFS.v16.0.17': [],\n",
       " 'GFS.v16.0.16': [],\n",
       " 'GFS.v16.0.15': [],\n",
       " 'GFS.v16.0.14': [],\n",
       " 'GFS.v16.0.13': [],\n",
       " 'GFS.v16.0.12': [],\n",
       " 'GFS.v16.0.11': [],\n",
       " 'GFS.v16.0.10': [],\n",
       " 'GFS.v16.0.9': [],\n",
       " 'GFS.v16.0.8': [],\n",
       " 'GFS.v16.0.7': [],\n",
       " 'GFS.v16.0.6': [],\n",
       " 'GFS.v16.0.5': [],\n",
       " 'GFS.v16.0.4': [],\n",
       " 'GFS.v16.0.3': [],\n",
       " 'GFS.v16.0.2': [],\n",
       " 'GFS.v16.0.1': [],\n",
       " 'GFS.v16.0.0': [],\n",
       " 'GFS_v15.2.1': [],\n",
       " 'GFS_v15.2.0': [],\n",
       " 'GFS_v15.1.4': [],\n",
       " 'GFS_v15.1.3': [],\n",
       " 'GFS_v15.1.2': [],\n",
       " 'GFS_v15.1.1': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tag2dataset['INPUTDATA_ROOT_BMIC']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a1140",
   "metadata": {},
   "source": [
    "__Remarks:__\n",
    "\n",
    "- For UFS RT framwork datasets, I do not have access to \"trunk-YYYYMMDD\" datasets. Does not exist for Hera or Orion, but for other HPCs such as Cheyenne, Jet, gaea, wcoss_cray, and theia\n",
    "\n",
    "- For SRW application: See ufs-srweather-app-develop/docs/UserGuide/source/InputOutputFiles.rst for ICS and LBCs. The external model, dates, & cycles are stated in a configuration files created by user and thus, the model analysis and model forecast datasets called to generate the ICs and LBCs through SRW preprocessor will be dependent upon the users' request. Thus, mapping the model analysis and model forecast datasets should be structured in the following fashion: {external_model_name: {date: {cycle_number}}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github_env",
   "language": "python",
   "name": "github_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
